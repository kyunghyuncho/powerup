----------------------------------------
Begin PBS Prologue Thu Oct 24 08:29:56 EDT 2013 1382617796
Job ID:		5238[11].hades
Username:	gulcehre
Group:		lisa
Nodes:		ngpu-a4-01
End PBS Prologue Thu Oct 24 08:29:59 EDT 2013 1382617799
----------------------------------------
book_unstarted_dct retrieved,  Dict{u'decay_factor': 0.048636689516568, u'jobman.experiment': u'powconvnet.train_pow.experiment', u'powerup_npieces2': 4, u'jobman.sql.priority': 1.0, u'init_mom': 0.389235586125694, u'final_mom': 0.648803972602221, u'yaml_string': u'!obj:pylearn2.train.Train {\n    dataset: &train !obj:pylearn2.datasets.mnist.MNIST {\n        which_set: \'train\',\n        one_hot: 1,\n        start: 0,\n        stop: 40000,\n    },\n    model: !obj:pylearn2.models.mlp.MLP {\n        batch_size: 128,\n        layers: [\n                !obj:pylearn2.models.powerup.Powerup {\n                     layer_name: \'h0\',\n                     num_units: %(powerup_nunits)i,\n                     num_pieces: %(powerup_npieces)i,\n                     p_mean: 1.0,\n                     post_bias: True,\n                     normalize: True,\n                     W_lr_scale: %(W_lr_scale)f,\n                     p_lr_scale: %(p_lr_scale)f,\n                     max_col_norm: %(max_col_norm)f,\n                     batch_size: 128,\n                     irange: .005,\n                 },\n                !obj:pylearn2.models.powerup.Powerup {\n                     layer_name: \'h1\',\n                     num_units: %(powerup_nunits2)i,\n                     num_pieces: %(powerup_npieces2)i,\n                     post_bias: True,\n                     normalize: True,\n                     p_mean: 1.0,\n                     W_lr_scale: %(W_lr_scale)f,\n                     p_lr_scale: %(p_lr_scale)f,\n                     max_col_norm: %(max_col_norm)f,\n                     batch_size: 128,\n                     irange: .005,\n                 },\n                 !obj:pylearn2.models.mlp.Softmax {\n                     max_col_norm: 1.83965,\n                     layer_name: \'y\',\n                     n_classes: 10,\n                     irange: .005\n                 }\n                ],\n        nvis: 784\n    },\n    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {\n        learning_rate: %(lr_rate)f,\n        init_momentum: %(init_mom)f,\n        monitoring_dataset:\n            {\n                \'train\' : *train,\n                \'valid\' : !obj:pylearn2.datasets.mnist.MNIST {\n                              which_set: \'train\',\n                              one_hot: 1,\n                              start: 50000,\n                              stop: 60000\n                          },\n                \'test\' : !obj:pylearn2.datasets.mnist.MNIST {\n                              which_set: \'test\',\n                              one_hot: 1,\n                          }\n            },\n       cost: !obj:pylearn2.costs.mlp.dropout.Dropout {\n           input_include_probs: { \'h0\' : .5, \'h1\' : .5 },\n           input_scales: { \'h0\': 2., \'h1\': 2.}\n       },\n       termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {\n            channel_name: "valid_y_misclass",\n            prop_decrease: 0.,\n            N: 100\n        },\n    },\n    extensions: [\n        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {\n             channel_name: \'valid_y_misclass\',\n             save_path: "%(save_path)sbest.pkl"\n        },\n        !obj:pylearn2.training_algorithms.sgd.MomentumAdjustor {\n            start: 1,\n            saturate: 250,\n            final_momentum: %(final_mom)f\n        },\n        !obj:pylearn2.training_algorithms.sgd.LinearDecayOverEpoch {\n            start: 1,\n            saturate: 250,\n            decay_factor: %(decay_factor)f\n        }\n    ],\n    save_path: "%(save_path)slast.pkl",\n    save_freq: 5\n}\n', u'powerup_npieces': 4, u'jobman.hash': -1604055201342753346, u'p_lr_scale': 0.989231712204477, u'max_col_norm': 2.2365, u'jobman.status': 0, u'W_lr_scale': 0.686641686942282, u'save_path': u'./abcdefg_', u'lr_rate': 0.773595016879846, u'powerup_nunits': 420, u'powerup_nunits2': 420}
caught exception (TransactionRollbackError) could not serialize access due to concurrent update
 'UPDATE powerup_mnist_finest_large_2ltrial SET status=%(status)s WHERE powerup_mnist_finest_large_2ltrial.id = %(powerup_mnist_finest_large_2ltrial_id)s' {'status': 1, 'powerup_mnist_finest_large_2ltrial_id': 13}
another process stole our dct. Waiting 8.374248 secs
waiting for 8 second
book_unstarted_dct retrieved,  Dict{u'decay_factor': 0.0319587305070652, u'jobman.experiment': u'powconvnet.train_pow.experiment', u'powerup_npieces2': 4, u'jobman.sql.priority': 1.0, u'init_mom': 0.463179314825184, u'final_mom': 0.741434141804538, u'yaml_string': u'!obj:pylearn2.train.Train {\n    dataset: &train !obj:pylearn2.datasets.mnist.MNIST {\n        which_set: \'train\',\n        one_hot: 1,\n        start: 0,\n        stop: 40000,\n    },\n    model: !obj:pylearn2.models.mlp.MLP {\n        batch_size: 128,\n        layers: [\n                !obj:pylearn2.models.powerup.Powerup {\n                     layer_name: \'h0\',\n                     num_units: %(powerup_nunits)i,\n                     num_pieces: %(powerup_npieces)i,\n                     p_mean: 1.0,\n                     post_bias: True,\n                     normalize: True,\n                     W_lr_scale: %(W_lr_scale)f,\n                     p_lr_scale: %(p_lr_scale)f,\n                     max_col_norm: %(max_col_norm)f,\n                     batch_size: 128,\n                     irange: .005,\n                 },\n                !obj:pylearn2.models.powerup.Powerup {\n                     layer_name: \'h1\',\n                     num_units: %(powerup_nunits2)i,\n                     num_pieces: %(powerup_npieces2)i,\n                     post_bias: True,\n                     normalize: True,\n                     p_mean: 1.0,\n                     W_lr_scale: %(W_lr_scale)f,\n                     p_lr_scale: %(p_lr_scale)f,\n                     max_col_norm: %(max_col_norm)f,\n                     batch_size: 128,\n                     irange: .005,\n                 },\n                 !obj:pylearn2.models.mlp.Softmax {\n                     max_col_norm: 1.83965,\n                     layer_name: \'y\',\n                     n_classes: 10,\n                     irange: .005\n                 }\n                ],\n        nvis: 784\n    },\n    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {\n        learning_rate: %(lr_rate)f,\n        init_momentum: %(init_mom)f,\n        monitoring_dataset:\n            {\n                \'train\' : *train,\n                \'valid\' : !obj:pylearn2.datasets.mnist.MNIST {\n                              which_set: \'train\',\n                              one_hot: 1,\n                              start: 50000,\n                              stop: 60000\n                          },\n                \'test\' : !obj:pylearn2.datasets.mnist.MNIST {\n                              which_set: \'test\',\n                              one_hot: 1,\n                          }\n            },\n       cost: !obj:pylearn2.costs.mlp.dropout.Dropout {\n           input_include_probs: { \'h0\' : .5, \'h1\' : .5 },\n           input_scales: { \'h0\': 2., \'h1\': 2.}\n       },\n       termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {\n            channel_name: "valid_y_misclass",\n            prop_decrease: 0.,\n            N: 100\n        },\n    },\n    extensions: [\n        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {\n             channel_name: \'valid_y_misclass\',\n             save_path: "%(save_path)sbest.pkl"\n        },\n        !obj:pylearn2.training_algorithms.sgd.MomentumAdjustor {\n            start: 1,\n            saturate: 250,\n            final_momentum: %(final_mom)f\n        },\n        !obj:pylearn2.training_algorithms.sgd.LinearDecayOverEpoch {\n            start: 1,\n            saturate: 250,\n            decay_factor: %(decay_factor)f\n        }\n    ],\n    save_path: "%(save_path)slast.pkl",\n    save_freq: 5\n}\n', u'powerup_npieces': 4, u'jobman.hash': 3017580742750161736, u'p_lr_scale': 0.974621402413606, u'max_col_norm': 2.1365, u'jobman.status': 0, u'W_lr_scale': 0.450558459621685, u'save_path': u'./abcdefg_', u'lr_rate': 0.456785768414963, u'powerup_nunits': 420, u'powerup_nunits2': 420}
Selected job id=22 in table=powerup_mnist_finest_large_2l in db=gulcehrc_db
----------------------------------------
Begin PBS Epilogue Thu Oct 24 11:35:11 EDT 2013 1382628911
Job ID:		5238[11].hades
Username:	gulcehre
Group:		lisa
Job Name:	dbi_9eae3e99c67-11
Session:	16651
Limits:		neednodes=1:ppn=1,nodes=1:ppn=1,walltime=47:59:59
Resources:	cput=01:32:08,mem=965244kb,vmem=48034996kb,walltime=03:05:11
Queue:		courte
Account:		
Nodes:	ngpu-a4-01
Killing leftovers...

End PBS Epilogue Thu Oct 24 11:35:11 EDT 2013 1382628911
----------------------------------------
