!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.mnist.MNIST {
        which_set: "train",
        one_hot: 1,
        start: 0,
        stop: 50000
    },
    model: !obj:pylearn2.models.mlp.MLP {
        batch_size: 200,
        layers:[
            !obj:pylearn2.models.powerup.Powerup {
                layer_name: 'h0',
                num_units: 12,
                centered_bias: True,
                num_pieces: 6,
                power_activ: "softhalf",
                p_lr_scale: 1.1,
                post_bias: True,
                normalize: True,
                max_col_norm: 1.9358,
                batch_size: 200,
                irange: .005
            },
            #!obj:pylearn2.models.powerup2.Powerup {
            #    layer_name: 'h1',
            #   num_units: 200,
            #    num_pieces: 2,
            #    n_in: 200,
            #    p_sampling_mode: "uniform",
            #    centered_bias: True,
            #    post_bias: True,
            #    normalize: True,
            #    max_col_norm: 1.9358,
            #    batch_size: 128,
            #    irange: .005
            #},
            !obj:pylearn2.models.mlp.Softmax {
                max_col_norm: 1.83965,
                layer_name: 'y',
                n_classes: 10,
                irange: .005
            }
        ],
        nvis: 784
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        learning_rate: 0.1,
        init_momentum: 0.5,
        train_iteration_mode: 'batchwise_shuffled_sequential',
        monitoring_dataset:
            {
                'train' : *train,
                'valid' : !obj:pylearn2.datasets.mnist.MNIST {
                              which_set: 'train',
                              one_hot: 1,
                              start: 50000,
                              stop: 60000
                          },
                'test' : !obj:pylearn2.datasets.mnist.MNIST {
                              which_set: 'test',
                              one_hot: 1,
                          }
            },
       #cost: !obj:pylearn2.costs.mlp.dropout.Dropout {
       #    input_include_probs: { 'h0' : .5, 'h1' : .5},
       #    input_scales: { 'h0': 2., 'h1': 2.}
       #},
       termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {
            channel_name: "test_y_misclass",
            prop_decrease: 0.,
            N: 100
        },
    },
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: 'test_y_misclass',
             save_path: "covertype_powerupsbest.pkl"
        },
        !obj:pylearn2.training_algorithms.sgd.MomentumAdjustor {
            start: 1,
            saturate: 250,
            final_momentum: 0.65
        },
        !obj:pylearn2.training_algorithms.sgd.LinearDecayOverEpoch {
            start: 1,
            saturate: 250,
            decay_factor: 0.003
        }
    ],
    save_path: "covertpe_powerup_last.pkl",
    save_freq: 5
}
